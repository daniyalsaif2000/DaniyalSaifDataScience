{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HiLNx9U2wyTN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Category:\n",
        "  BOOKS = \"BOOKS\"\n",
        "  CLOTHING = \"CLOTHING\"\n",
        "\n",
        "train_x = ['i love the book', 'this is a great book','the fit is great','i love the shoes']\n",
        "train_y = [Category.BOOKS, Category.BOOKS, Category.CLOTHING, Category.CLOTHING]"
      ],
      "metadata": {
        "id": "PClywNVgw5LY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(binary=True)"
      ],
      "metadata": {
        "id": "_eZpblrBxGgR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = vectorizer.fit_transform(train_x)\n",
        "\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(vectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwAE2Ui6xecP",
        "outputId": "849353fa-9010-45b6-8855-c3feae93ef84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']\n",
            "[[1 0 0 0 1 0 1 0]\n",
            " [1 0 1 1 0 0 0 1]\n",
            " [0 1 1 1 0 0 1 0]\n",
            " [0 0 0 0 1 1 1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "8FKYD4SYxhfF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svm = svm.SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "fBFrWfgvyHow"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svm.fit(vectors, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLcd7Vm3zAc_",
        "outputId": "f558b5c2-669b-433a-b223-efd64b4e32ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = vectorizer.transform(['shoes are weird'])"
      ],
      "metadata": {
        "id": "CStViVRFzHpv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svm.predict(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK3hzX7szkFE",
        "outputId": "f3ba6b38-e53d-423b-adc4-b0fb9e9c5c56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CLOTHING'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Word Vectors"
      ],
      "metadata": {
        "id": "S_9y9OsczosZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "HX9RoKvd5B8w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "W6dctCJ65XSR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [nlp(text) for text in train_x]"
      ],
      "metadata": {
        "id": "rdb91nVJ5eQS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_word_vector = [x.vector for x in docs]"
      ],
      "metadata": {
        "id": "o6oklUxf8RFu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "fZoBnY9z9kac"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_wv = svm.SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "DGMVCcJa9qnA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_wv.fit(train_x_word_vector, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydEsgr7694r6",
        "outputId": "601076b7-ec0a-4d67-a23d-471f106ad108"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x =['i love the books']\n",
        "test_doc = [nlp(text) for text in test_x]\n",
        "test_vectors = [x.vector for x in test_doc]\n"
      ],
      "metadata": {
        "id": "J6LJhm0R99ki"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " clf_wv.predict(test_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMBZ4rcm-kqc",
        "outputId": "d34d812f-1919-4add-ca32-c7d4fbf53b52"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CLOTHING'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**REGEX**"
      ],
      "metadata": {
        "id": "uOKQ6s_LGQc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "arv-9ijr-xa-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regexp = re.compile(r\"story|book|bread\")"
      ],
      "metadata": {
        "id": "jYlQrW_eE8qq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases = ['I liked that story', \"the car treaded up the hill book\", \"this hat is nice\"]"
      ],
      "metadata": {
        "id": "-wqThqRIC7ov"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = []\n",
        "\n",
        "for phrase in phrases:\n",
        "  if re.search(regexp,phrase):\n",
        "    matches.append(phrase)\n",
        "\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C13egCBC9u6",
        "outputId": "8d4da280-0297-4522-84a7-219a8787549c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I liked that story', 'the car treaded up the hill book']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CTQ6bwFrGEQx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming and Lemmatization**"
      ],
      "metadata": {
        "id": "82bcRw3fPYgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "yli5S6lgPaIp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elw1TNRWPd6H",
        "outputId": "ff0dd401-a302-4036-ed39-1ea95a23f184"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize  \n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "Cj1c4hUwPmyy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "_NqDPFrEPxle"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = \"Reading the books and playing\"\n"
      ],
      "metadata": {
        "id": "YxmIpav8QNIZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = word_tokenize(phrase)"
      ],
      "metadata": {
        "id": "XUsMv9CJQ1l-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words = []\n",
        "for words in word:\n",
        "  stemmed_words.append(stemmer.stem(words))\n",
        "  \n",
        "\n",
        "\" \".join(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "hxGVXwH9Q82B",
        "outputId": "f34b7b89-3586-4594-913a-d1d5b2266c2c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read the book and play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xd0XqKm-T-Hp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**"
      ],
      "metadata": {
        "id": "oCWMAcqKUgNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "dcA1NmhnUjM3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " lematizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "B2ecCU9ZUnNv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = \"reading and reads and reader leaving and leaves the books and playing\"\n",
        "word = word_tokenize(phrase)"
      ],
      "metadata": {
        "id": "Lb6tr5qa_LwZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatized_words =[]\n",
        "\n",
        "# for words in word:\n",
        "#   lemmatized_words.append(lematizer.lemmatize(words,pos='v'))\n",
        "\n",
        "# \" \".join(lemmatized_words)"
      ],
      "metadata": {
        "id": "USVFznbRXVzh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lem_words(words):\n",
        "  [lematizer.lemmatize(words) for words in words]\n",
        "  print(\" \".join(lemmatized_words))"
      ],
      "metadata": {
        "id": "OhhuWhI-_dGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lem_words(words)"
      ],
      "metadata": {
        "id": "ITdMNe3n_iVg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lo8ciNwhCHAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stopwords**"
      ],
      "metadata": {
        "id": "CHHR67FbC_mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ojXIpBSPDCGP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "OOP_xm_IDQWC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uFN8duvDaw0",
        "outputId": "5ea2983a-6133-4cb6-aaa5-75b07015fae8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'This is an example sentence showing removal of the would was a then stopwords'"
      ],
      "metadata": {
        "id": "o7XuVvFqDcyP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(phrase)\n",
        "\n",
        "stripped_phase = []\n",
        "\n",
        "for word in words:\n",
        "  if word not in stop_words:\n",
        "    stripped_phase.append(word)\n",
        "\n",
        "\" \".join(stripped_phase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "PYCx-ZYqGNvd",
        "outputId": "34ba994f-cd91-434a-d69b-0544f28c92f0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This example sentence showing removal would stopwords'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vgNMnb_Mh7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}